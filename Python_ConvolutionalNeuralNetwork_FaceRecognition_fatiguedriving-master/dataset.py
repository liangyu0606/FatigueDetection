"""
æ•°æ®é›†åŠ è½½å™¨
"""
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pickle
from typing import List, Dict, Tuple
import cv2
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

from config import *
from utils import augment_image

class YawnDataset(Dataset):
    """æ‰“å“ˆæ¬ æ£€æµ‹æ•°æ®é›†"""
    
    def __init__(self, samples: List[Dict], transform=None, augment=False):
        """
        Args:
            samples: é¢„å¤„ç†åçš„æ ·æœ¬åˆ—è¡¨
            transform: æ•°æ®å˜æ¢
            augment: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        """
        self.samples = samples
        self.transform = transform
        self.augment = augment
        
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        self.labels = [sample['label'] for sample in samples]
        self.class_counts = np.bincount(self.labels)
        
        print(f"æ•°æ®é›†å¤§å°: {len(samples)}")
        print(f"ç±»åˆ«åˆ†å¸ƒ: {dict(enumerate(self.class_counts))}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        faces = sample['faces']  # (sequence_length, height, width, channels)
        landmarks = sample['landmarks']  # (sequence_length, 68, 2)
        label = sample['label']
        
        # æ•°æ®å¢å¼º
        if self.augment:
            augmented_faces = []
            augmented_landmarks = []
            
            for i in range(len(faces)):
                face = faces[i]
                landmark = landmarks[i]
                
                # åº”ç”¨å¢å¼º
                aug_face, aug_landmark = augment_image(face, landmark, AUGMENTATION)
                augmented_faces.append(aug_face)
                augmented_landmarks.append(aug_landmark)
            
            faces = np.array(augmented_faces)
            landmarks = np.array(augmented_landmarks)
        
        # è½¬æ¢ä¸ºtensor
        faces = torch.from_numpy(faces).float()
        landmarks = torch.from_numpy(landmarks).float()
        label = torch.tensor(label, dtype=torch.long)
        
        # è°ƒæ•´ç»´åº¦é¡ºåº: (sequence_length, height, width, channels) -> (sequence_length, channels, height, width)
        faces = faces.permute(0, 3, 1, 2)
        
        # å±•å¹³ç‰¹å¾ç‚¹: (sequence_length, 68, 2) -> (sequence_length, 136)
        landmarks = landmarks.reshape(landmarks.size(0), -1)
        
        # å½’ä¸€åŒ–åƒç´ å€¼
        faces = faces / 255.0
        
        return faces, landmarks, label
    
    def get_class_weights(self):
        """è®¡ç®—ç±»åˆ«æƒé‡ç”¨äºå¤„ç†ä¸å¹³è¡¡æ•°æ®"""
        class_weights = compute_class_weight(
            'balanced',
            classes=np.unique(self.labels),
            y=self.labels
        )
        return torch.tensor(class_weights, dtype=torch.float32)

def load_processed_data(data_path: str) -> List[Dict]:
    """åŠ è½½é¢„å¤„ç†åçš„æ•°æ®"""
    with open(data_path, 'rb') as f:
        samples = pickle.load(f)
    return samples

def balance_dataset(samples: List[Dict], balance_ratio: float = 1.0) -> List[Dict]:
    """
    å¹³è¡¡æ•°æ®é›†

    Args:
        samples: åŸå§‹æ ·æœ¬
        balance_ratio: æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ (positive/negative)

    Returns:
        balanced_samples: å¹³è¡¡åçš„æ ·æœ¬
    """
    positive_samples = [s for s in samples if s['label'] == 1]
    negative_samples = [s for s in samples if s['label'] == 0]

    print(f"åŸå§‹æ•°æ® - æ­£æ ·æœ¬: {len(positive_samples)}, è´Ÿæ ·æœ¬: {len(negative_samples)}")

    if len(positive_samples) == 0:
        print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ­£æ ·æœ¬ï¼")
        return samples

    if len(negative_samples) == 0:
        print("âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰è´Ÿæ ·æœ¬ï¼")
        return samples

    # è°ƒè¯•æ¨¡å¼ä¸‹çš„ç‰¹æ®Šå¤„ç†
    if DEBUG_MODE:
        # å¦‚æœæ­£æ ·æœ¬å¤ªå°‘ï¼Œå¤§é‡ä¸Šé‡‡æ ·
        if len(negative_samples) / len(positive_samples) > 10:
            print("ğŸ” è°ƒè¯•æ¨¡å¼ï¼šæ­£æ ·æœ¬ä¸¥é‡ä¸è¶³ï¼Œè¿›è¡Œå¤§é‡ä¸Šé‡‡æ ·")
            target_positive = min(len(negative_samples) // 2, len(positive_samples) * 20)
            positive_samples = np.random.choice(
                positive_samples,
                size=target_positive,
                replace=True
            ).tolist()

            # é€‚å½“ä¸‹é‡‡æ ·è´Ÿæ ·æœ¬
            target_negative = len(positive_samples) * 2
            if target_negative < len(negative_samples):
                negative_samples = np.random.choice(
                    negative_samples,
                    size=target_negative,
                    replace=False
                ).tolist()
        else:
            # æ­£å¸¸å¹³è¡¡
            target_ratio = min(balance_ratio, 0.5)  # è°ƒè¯•æ¨¡å¼ä¸‹æœ€å¤š1:2
            if len(positive_samples) * target_ratio <= len(negative_samples):
                target_negative = int(len(positive_samples) / target_ratio)
                negative_samples = np.random.choice(
                    negative_samples,
                    size=target_negative,
                    replace=False
                ).tolist()
            else:
                target_positive = int(len(negative_samples) * target_ratio)
                positive_samples = np.random.choice(
                    positive_samples,
                    size=target_positive,
                    replace=True
                ).tolist()
    else:
        # æ­£å¼æ¨¡å¼çš„å¹³è¡¡ç­–ç•¥
        if len(positive_samples) * balance_ratio <= len(negative_samples):
            # ä¸‹é‡‡æ ·è´Ÿæ ·æœ¬
            target_negative = int(len(positive_samples) / balance_ratio)
            negative_samples = np.random.choice(
                negative_samples,
                size=target_negative,
                replace=False
            ).tolist()
        else:
            # ä¸Šé‡‡æ ·æ­£æ ·æœ¬
            target_positive = int(len(negative_samples) * balance_ratio)
            positive_samples = np.random.choice(
                positive_samples,
                size=target_positive,
                replace=True
            ).tolist()

    balanced_samples = positive_samples + negative_samples
    np.random.shuffle(balanced_samples)

    print(f"å¹³è¡¡åæ•°æ® - æ­£æ ·æœ¬: {len(positive_samples)}, è´Ÿæ ·æœ¬: {len(negative_samples)}")
    print(f"å¹³è¡¡æ¯”ä¾‹: {len(positive_samples)/len(negative_samples):.3f}")

    return balanced_samples

def create_data_loaders(samples: List[Dict], 
                       train_ratio: float = TRAIN_SPLIT,
                       val_ratio: float = VAL_SPLIT,
                       test_ratio: float = TEST_SPLIT,
                       balance_train: bool = True) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    åˆ›å»ºæ•°æ®åŠ è½½å™¨
    
    Args:
        samples: é¢„å¤„ç†åçš„æ ·æœ¬
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
        balance_train: æ˜¯å¦å¹³è¡¡è®­ç»ƒé›†
        
    Returns:
        train_loader, val_loader, test_loader
    """
    # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
    total_ratio = train_ratio + val_ratio + test_ratio
    train_ratio /= total_ratio
    val_ratio /= total_ratio
    test_ratio /= total_ratio
    
    # åˆ†å±‚åˆ’åˆ†æ•°æ®é›†
    labels = [sample['label'] for sample in samples]
    
    # é¦–å…ˆåˆ†å‡ºè®­ç»ƒé›†å’Œä¸´æ—¶é›†
    train_samples, temp_samples, train_labels, temp_labels = train_test_split(
        samples, labels,
        test_size=(val_ratio + test_ratio),
        stratify=labels,
        random_state=42
    )
    
    # å†ä»ä¸´æ—¶é›†ä¸­åˆ†å‡ºéªŒè¯é›†å’Œæµ‹è¯•é›†
    val_samples, test_samples = train_test_split(
        temp_samples,
        test_size=test_ratio / (val_ratio + test_ratio),
        stratify=temp_labels,
        random_state=42
    )
    
    print(f"æ•°æ®é›†åˆ’åˆ†:")
    print(f"è®­ç»ƒé›†: {len(train_samples)} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_samples)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_samples)} æ ·æœ¬")
    
    # å¹³è¡¡è®­ç»ƒé›†
    if balance_train:
        train_samples = balance_dataset(train_samples)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = YawnDataset(train_samples, augment=True)
    val_dataset = YawnDataset(val_samples, augment=False)
    test_dataset = YawnDataset(test_samples, augment=False)
    
    # æ ¹æ®è°ƒè¯•æ¨¡å¼é€‰æ‹©æ‰¹æ¬¡å¤§å°å’Œå·¥ä½œè¿›ç¨‹æ•°
    batch_size = DEBUG_BATCH_SIZE if DEBUG_MODE else BATCH_SIZE
    # Windowsä¸‹ä½¿ç”¨å•è¿›ç¨‹é¿å…å¤šè¿›ç¨‹é—®é¢˜
    num_workers = 0

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=False  # CPUæ¨¡å¼ä¸‹å…³é—­pin_memory
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=False
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=False
    )
    
    return train_loader, val_loader, test_loader

def analyze_dataset(samples: List[Dict]):
    """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    print("=== æ•°æ®é›†åˆ†æ ===")
    
    # åŸºæœ¬ç»Ÿè®¡
    total_samples = len(samples)
    positive_samples = sum(1 for s in samples if s['label'] == 1)
    negative_samples = total_samples - positive_samples
    
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"æ­£æ ·æœ¬æ•° (æ‰“å“ˆæ¬ ): {positive_samples} ({positive_samples/total_samples*100:.1f}%)")
    print(f"è´Ÿæ ·æœ¬æ•° (æ­£å¸¸/è¯´è¯): {negative_samples} ({negative_samples/total_samples*100:.1f}%)")
    print(f"æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹: {positive_samples/negative_samples:.3f}")
    
    # è§†é¢‘æ¥æºç»Ÿè®¡
    video_sources = {}
    for sample in samples:
        video_path = sample['video_path']
        if 'Dash' in video_path:
            source = 'Dash'
        elif 'Mirror' in video_path:
            source = 'Mirror'
        else:
            source = 'Unknown'
        
        if 'Female' in video_path:
            gender = 'Female'
        elif 'Male' in video_path:
            gender = 'Male'
        else:
            gender = 'Unknown'
        
        key = f"{source}_{gender}"
        if key not in video_sources:
            video_sources[key] = {'total': 0, 'positive': 0}
        
        video_sources[key]['total'] += 1
        if sample['label'] == 1:
            video_sources[key]['positive'] += 1
    
    print("\n=== æŒ‰æ¥æºç»Ÿè®¡ ===")
    for source, stats in video_sources.items():
        pos_ratio = stats['positive'] / stats['total'] * 100 if stats['total'] > 0 else 0
        print(f"{source}: {stats['total']} æ ·æœ¬, {stats['positive']} æ­£æ ·æœ¬ ({pos_ratio:.1f}%)")

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    data_path = os.path.join(PROCESSED_DATA_PATH, "processed_samples.pkl")
    
    if os.path.exists(data_path):
        samples = load_processed_data(data_path)
        analyze_dataset(samples)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = create_data_loaders(samples)
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        for faces, landmarks, labels in train_loader:
            print(f"æ‰¹æ¬¡å½¢çŠ¶ - äººè„¸: {faces.shape}, ç‰¹å¾ç‚¹: {landmarks.shape}, æ ‡ç­¾: {labels.shape}")
            break
    else:
        print(f"é¢„å¤„ç†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        print("è¯·å…ˆè¿è¡Œ data_preprocessing.py è¿›è¡Œæ•°æ®é¢„å¤„ç†")
