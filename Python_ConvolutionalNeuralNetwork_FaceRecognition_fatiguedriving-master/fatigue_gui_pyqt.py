"""
ç–²åŠ³æ£€æµ‹GUIç•Œé¢ - PyQtç‰ˆæœ¬
ä¿æŒåŸæœ‰çš„æ£€æµ‹é€»è¾‘ï¼Œåªæ›´æ¢å‰ç«¯ç•Œé¢æŠ€æœ¯ä»Tkinteråˆ°PyQt
"""
import cv2
import torch
import numpy as np
import dlib
from collections import deque
import time
import threading
import os
import sys

from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                            QHBoxLayout, QGridLayout, QLabel, QPushButton, 
                            QProgressBar, QTextEdit, QGroupBox, QFrame,
                            QScrollArea, QSplitter, QMessageBox, QSlider)
from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QThread, pyqtSlot
from PyQt5.QtGui import QPixmap, QImage, QFont, QPalette, QColor

from config import *
from model import create_model
from utils import extract_face_landmarks, normalize_landmarks

class VideoThread(QThread):
    """è§†é¢‘å¤„ç†çº¿ç¨‹ - ä¿æŒåŸæœ‰æ£€æµ‹é€»è¾‘"""
    frame_ready = pyqtSignal(np.ndarray, bool, float, int)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent
        self.running = False
        
    def run(self):
        """æ£€æµ‹å¾ªç¯ - å®Œå…¨ä¿æŒåŸæœ‰é€»è¾‘"""
        while self.running:
            try:
                ret, frame = self.parent.cap.read()
                if not ret:
                    print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break

                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # é¢„å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                face_img, landmarks_norm, face_rect = self.parent._preprocess_frame(frame)
                face_detected = face_img is not None

                # è·å–åŸå§‹landmarksç”¨äºMAR/EARè®¡ç®—
                if face_detected:
                    original_face_img, original_landmarks = extract_face_landmarks(frame, self.parent.detector, self.parent.predictor)
                
                yawn_prob = 0.0
                prediction = 0
                
                if face_detected:
                    self.parent.face_buffer.append(face_img)
                    self.parent.landmark_buffer.append(landmarks_norm)

                    # å¦‚æœç¼“å†²åŒºæ»¡äº†ï¼Œè¿›è¡Œé¢„æµ‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    if len(self.parent.face_buffer) >= SEQUENCE_LENGTH:
                        yawn_prob, model_prediction = self.parent._predict_yawn()
                        self.parent.total_predictions += 1

                        # è®¡ç®—å½“å‰å¸§çš„å˜´éƒ¨é•¿å®½æ¯”å’Œçœ¼éƒ¨é•¿å®½æ¯”ï¼ˆä½¿ç”¨åŸå§‹landmarksï¼‰
                        current_mar = self.parent._calculate_mouth_aspect_ratio(original_landmarks)
                        current_ear = self.parent._calculate_eye_aspect_ratio(original_landmarks)

                        # æ£€æµ‹çœ¨çœ¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                        blink_detected = self.parent._detect_blink(current_ear)

                        # æ–°çš„æ£€æµ‹é€»è¾‘ï¼šæ¨¡å‹é¢„æµ‹ + MARé˜ˆå€¼çš„ç»„åˆåˆ¤æ–­ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                        model_says_yawn = yawn_prob > self.parent.yawn_threshold.get()
                        mar_says_yawn = current_mar > self.parent.mar_threshold.get()

                        # æœ€ç»ˆåˆ¤æ–­ï¼šä¸¤ä¸ªæ¡ä»¶éƒ½æ»¡è¶³æ‰è®¤ä¸ºæ˜¯æ‰“å“ˆæ¬ ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                        final_prediction = 1 if (model_says_yawn and mar_says_yawn) else 0

                        # æ›´æ–°è¿ç»­æ£€æµ‹è®¡æ•° - ä½¿ç”¨å¹³æ»‘è¡°å‡æœºåˆ¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                        current_time = time.time()
                        if final_prediction == 1:
                            # æ£€æµ‹åˆ°æ‰“å“ˆæ¬ ï¼šå¢åŠ è®¡æ•°ï¼Œæ›´æ–°æœ€åæ£€æµ‹æ—¶é—´
                            self.parent.consecutive_yawns += 1
                            self.parent.last_detection_time = current_time
                            self.parent.no_detection_frames = 0  # é‡ç½®æœªæ£€æµ‹å¸§æ•°
                            print(f"ğŸ” æ‰“å“ˆæ¬ æ£€æµ‹: æ¨¡å‹={yawn_prob:.3f}({'âœ“' if model_says_yawn else 'âœ—'}), MAR={current_mar:.3f}({'âœ“' if mar_says_yawn else 'âœ—'}), è¿ç»­={self.parent.consecutive_yawns}")
                        else:
                            # æœªæ£€æµ‹åˆ°æ‰“å“ˆæ¬ ï¼šä½¿ç”¨å¹³æ»‘è¡°å‡
                            self.parent.no_detection_frames += 1
                            
                            # å¦‚æœæœ‰ä¹‹å‰çš„æ£€æµ‹è®°å½•ï¼Œåˆ™å¼€å§‹è¡°å‡
                            if self.parent.consecutive_yawns > 0:
                                # è®¡ç®—è¡°å‡é‡ï¼šåŸºäºæ—¶é—´çš„è¡°å‡
                                if self.parent.last_detection_time > 0:
                                    time_since_last = current_time - self.parent.last_detection_time
                                    # æ¯ç§’è¡°å‡decay_rateå¸§ï¼Œä½†è‡³å°‘ä¿æŒ1ç§’ä¸è¡°å‡
                                    if time_since_last > 1.0:  # 1ç§’åå¼€å§‹è¡°å‡
                                        decay_amount = int((time_since_last - 1.0) * self.parent.decay_rate)
                                        self.parent.consecutive_yawns = max(0, self.parent.consecutive_yawns - decay_amount)
                                        
                                        if self.parent.consecutive_yawns == 0:
                                            print(f"ğŸ“‰ è¿›åº¦æ¡è¡°å‡è‡³é›¶ï¼ˆæœªæ£€æµ‹{self.parent.no_detection_frames}å¸§ï¼Œæ—¶é—´é—´éš”{time_since_last:.1f}ç§’ï¼‰")
                                        else:
                                            print(f"ğŸ“‰ è¿›åº¦æ¡è¡°å‡: {self.parent.consecutive_yawns}ï¼ˆæœªæ£€æµ‹{self.parent.no_detection_frames}å¸§ï¼‰")
                                else:
                                    # å¦‚æœæ²¡æœ‰æ—¶é—´è®°å½•ï¼Œç«‹å³å¼€å§‹è¡°å‡
                                    if self.parent.no_detection_frames > 30:  # 30å¸§åå¼€å§‹è¡°å‡ï¼ˆçº¦1ç§’ï¼‰
                                        self.parent.consecutive_yawns = max(0, self.parent.consecutive_yawns - 1)
                            else:
                                # å¦‚æœconsecutive_yawnså·²ç»æ˜¯0ï¼Œä¿æŒä¸º0
                                self.parent.consecutive_yawns = 0

                        # æ£€æŸ¥æ˜¯å¦è§¦å‘è­¦æŠ¥ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                        if (self.parent.consecutive_yawns >= self.parent.consecutive_threshold and
                            (current_time - self.parent.last_yawn_time) > self.parent.alert_cooldown.get()):
                            self.parent.yawn_count += 1
                            self.parent.last_yawn_time = current_time
                            self.parent.recent_yawns.append(current_time)
                            print(f"ğŸš¨ è§¦å‘è­¦æŠ¥ï¼è¿ç»­{self.parent.consecutive_yawns}å¸§æ£€æµ‹åˆ°æ‰“å“ˆæ¬ ")

                        # æ›´æ–°predictionå˜é‡ç”¨äºGUIæ˜¾ç¤º
                        prediction = final_prediction

                    # åœ¨äººè„¸ä¸Šç»˜åˆ¶ç‰¹å¾ç‚¹å’Œäººè„¸æ¡†ï¼ˆä½¿ç”¨å½’ä¸€åŒ–çš„landmarksï¼‰
                    frame = self.parent._draw_face_landmarks(frame, face_rect, landmarks_norm)
                else:
                    # æœªæ£€æµ‹åˆ°äººè„¸æ—¶çš„è¡°å‡é€»è¾‘ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    if self.parent.consecutive_yawns > 0:
                        current_time = time.time()
                        self.parent.no_detection_frames += 1
                        
                        # å¦‚æœæœ‰ä¹‹å‰çš„æ£€æµ‹è®°å½•ï¼Œåˆ™å¼€å§‹è¡°å‡
                        if self.parent.last_detection_time > 0:
                            time_since_last = current_time - self.parent.last_detection_time
                            # æœªæ£€æµ‹åˆ°äººè„¸æ—¶ï¼Œè¡°å‡æ›´å¿«ä¸€äº›
                            if time_since_last > 0.5:  # 0.5ç§’åå¼€å§‹è¡°å‡
                                decay_amount = int((time_since_last - 0.5) * self.parent.decay_rate * 1.5)  # è¡°å‡é€Ÿåº¦1.5å€
                                old_consecutive = self.parent.consecutive_yawns
                                self.parent.consecutive_yawns = max(0, self.parent.consecutive_yawns - decay_amount)
                                
                                if old_consecutive != self.parent.consecutive_yawns:
                                    if self.parent.consecutive_yawns == 0:
                                        print(f"ğŸ“‰ æœªæ£€æµ‹åˆ°äººè„¸ï¼Œè¿›åº¦æ¡è¡°å‡è‡³é›¶ï¼ˆæœªæ£€æµ‹{self.parent.no_detection_frames}å¸§ï¼‰")
                                    else:
                                        print(f"ğŸ“‰ æœªæ£€æµ‹åˆ°äººè„¸ï¼Œè¿›åº¦æ¡è¡°å‡: {self.parent.consecutive_yawns}")
                        else:
                            # å¦‚æœæ²¡æœ‰æ—¶é—´è®°å½•ï¼Œè¾ƒå¿«è¡°å‡
                            if self.parent.no_detection_frames > 15:  # 15å¸§åå¼€å§‹è¡°å‡ï¼ˆçº¦0.5ç§’ï¼‰
                                self.parent.consecutive_yawns = max(0, self.parent.consecutive_yawns - 1)

                # ä¿å­˜çŠ¶æ€å˜é‡ä¾›GUIæ›´æ–°ä½¿ç”¨
                self.parent._last_face_detected = face_detected
                self.parent._last_yawn_prob = yawn_prob
                self.parent._last_prediction = prediction
                if face_detected and len(self.parent.face_buffer) >= SEQUENCE_LENGTH:
                    # ä¿å­˜MARå’ŒEARç”¨äºGUIæ˜¾ç¤ºï¼ˆä½¿ç”¨åŸå§‹landmarksï¼‰
                    self.parent._last_mar = self.parent._calculate_mouth_aspect_ratio(original_landmarks)
                    self.parent._last_ear = self.parent._calculate_eye_aspect_ratio(original_landmarks)

                # å‘é€ä¿¡å·æ›´æ–°GUI
                self.frame_ready.emit(frame, face_detected, yawn_prob, prediction)
                
                self.msleep(33)  # çº¦30fps
                
            except Exception as e:
                print(f"âŒ æ£€æµ‹å¾ªç¯é”™è¯¯: {e}")
                break

class FatigueDetectionGUI(QMainWindow):
    def __init__(self, model_path: str):
        super().__init__()
        self.model_path = model_path
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–ä¸»çª—å£
        self.setWindowTitle("ç–²åŠ³é©¾é©¶æ£€æµ‹ç³»ç»Ÿ - PyQtç‰ˆæœ¬")
        self.setGeometry(100, 100, 1400, 900)
        
        # åŠ è½½æ¨¡å‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.model = self._load_model()
        
        # åˆå§‹åŒ–dlibï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = dlib.shape_predictor(DLIB_PREDICTOR_PATH)
        
        # æ‘„åƒå¤´
        self.cap = None
        self.video_thread = None
        self.camera_index = self._detect_available_camera()
        
        # æ£€æµ‹å‚æ•°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼Œä½¿ç”¨ç®€å•çš„ç±»æ¥æ¨¡æ‹Ÿtkinterå˜é‡ï¼‰
        class SimpleVar:
            def __init__(self, value):
                self._value = value
            def get(self):
                return self._value
            def set(self, value):
                self._value = value

        self.yawn_threshold = SimpleVar(0.6)
        self.mar_threshold = SimpleVar(0.6)
        self.consecutive_threshold = 30
        self.alert_cooldown = SimpleVar(5.0)
        self.current_mode = "balanced"
        
        # ç¼“å†²åŒºï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.face_buffer = deque(maxlen=SEQUENCE_LENGTH)
        self.landmark_buffer = deque(maxlen=SEQUENCE_LENGTH)
        
        # çŠ¶æ€å˜é‡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.yawn_count = 0
        self.blink_count = 0
        self.total_predictions = 0
        self.consecutive_yawns = 0
        self.session_start_time = None
        self.last_yawn_time = 0
        
        # è¿›åº¦æ¡å¹³æ»‘æ§åˆ¶å˜é‡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.last_detection_time = 0
        self.decay_rate = 2.0
        self.no_detection_frames = 0
        
        # ç–²åŠ³çŠ¶æ€è¯„ä¼°ç›¸å…³ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.recent_yawns = []
        self.recent_blinks = []
        self.fatigue_window = 60
        self.last_blink_time = 0
        self.eye_closed_frames = 0
        self.eye_closed_threshold = 10
        self.long_eye_closed_threshold = 90
        self.eye_closed_start_time = None
        
        # åˆ›å»ºGUI
        self._create_gui()
        
        # è®¾ç½®æ ·å¼
        self._set_style()
        
        # å®šæ—¶å™¨æ›´æ–°GUI
        self.timer = QTimer()
        self.timer.timeout.connect(self._update_gui)
        self.timer.start(100)  # 100msæ›´æ–°ä¸€æ¬¡
        
        # åº”ç”¨é»˜è®¤çš„å¹³è¡¡æ¨¡å¼
        self._apply_preset('balanced')

    def _detect_available_camera(self):
        """è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æ‘„åƒå¤´ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        print("ğŸ” æ­£åœ¨æ£€æµ‹å¯ç”¨æ‘„åƒå¤´...")
        
        for index in range(6):
            try:
                cap = cv2.VideoCapture(index)
                if cap.isOpened():
                    ret, frame = cap.read()
                    cap.release()
                    if ret and frame is not None:
                        print(f"âœ… æ£€æµ‹åˆ°å¯ç”¨æ‘„åƒå¤´: ç´¢å¼• {index}")
                        return index
                else:
                    cap.release()
            except Exception as e:
                continue
        
        print("âŒ æœªæ£€æµ‹åˆ°å¯ç”¨æ‘„åƒå¤´ï¼Œä½¿ç”¨é»˜è®¤ç´¢å¼• 0")
        return 0

    def _load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        try:
            model = create_model().to(self.device)
            checkpoint = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

    def _create_gui(self):
        """åˆ›å»ºGUIç•Œé¢"""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)

        # ä¸»å¸ƒå±€
        main_layout = QHBoxLayout(central_widget)

        # åˆ›å»ºåˆ†å‰²å™¨
        splitter = QSplitter(Qt.Horizontal)
        main_layout.addWidget(splitter)

        # å·¦ä¾§é¢æ¿
        left_panel = self._create_left_panel()
        splitter.addWidget(left_panel)

        # å³ä¾§é¢æ¿
        right_panel = self._create_right_panel()
        splitter.addWidget(right_panel)

        # è®¾ç½®åˆ†å‰²æ¯”ä¾‹
        splitter.setSizes([800, 600])

    def _create_left_panel(self):
        """åˆ›å»ºå·¦ä¾§é¢æ¿"""
        left_widget = QWidget()
        left_layout = QVBoxLayout(left_widget)

        # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        video_group = QGroupBox("è§†é¢‘é¢„è§ˆ")
        video_group.setFont(QFont("Arial", 12, QFont.Bold))
        video_layout = QVBoxLayout(video_group)

        self.video_label = QLabel("ç­‰å¾…æ‘„åƒå¤´å¯åŠ¨...")
        self.video_label.setMinimumSize(640, 480)
        self.video_label.setStyleSheet("""
            QLabel {
                background-color: #333333;
                color: white;
                font-size: 16px;
                border: 2px solid #555555;
            }
        """)
        self.video_label.setAlignment(Qt.AlignCenter)
        video_layout.addWidget(self.video_label)

        left_layout.addWidget(video_group)

        # æ§åˆ¶æŒ‰é’®
        control_group = QGroupBox("æ§åˆ¶é¢æ¿")
        control_group.setFont(QFont("Arial", 10, QFont.Bold))
        control_layout = QHBoxLayout(control_group)

        self.start_btn = QPushButton("ğŸš€ å¼€å§‹æ£€æµ‹")
        self.start_btn.setStyleSheet("""
            QPushButton {
                background-color: #4CAF50;
                color: white;
                font-size: 12px;
                font-weight: bold;
                padding: 10px 20px;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
        """)
        self.start_btn.clicked.connect(self._start_detection)

        self.stop_btn = QPushButton("â¹ï¸ åœæ­¢æ£€æµ‹")
        self.stop_btn.setStyleSheet("""
            QPushButton {
                background-color: #f44336;
                color: white;
                font-size: 12px;
                font-weight: bold;
                padding: 10px 20px;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #da190b;
            }
        """)
        self.stop_btn.clicked.connect(self._stop_detection)
        self.stop_btn.setEnabled(False)

        control_layout.addWidget(self.start_btn)
        control_layout.addWidget(self.stop_btn)
        control_layout.addStretch()

        left_layout.addWidget(control_group)

        # å½“å‰è®¾ç½®
        settings_group = QGroupBox("å½“å‰è®¾ç½®")
        settings_group.setFont(QFont("Arial", 10, QFont.Bold))
        settings_layout = QVBoxLayout(settings_group)

        self.current_mode_label = QLabel("å½“å‰æ¨¡å¼: âš–ï¸ å¹³è¡¡æ¨¡å¼")
        self.current_mode_label.setFont(QFont("Arial", 11, QFont.Bold))
        self.current_mode_label.setStyleSheet("color: #4CAF50;")

        self.current_params_label = QLabel("æ¨¡å‹é˜ˆå€¼: 0.60 | MARé˜ˆå€¼: 0.60 | è¿ç»­é˜ˆå€¼: 30å¸§ | å†·å´: 5.0ç§’")
        self.current_params_label.setFont(QFont("Arial", 9))
        self.current_params_label.setStyleSheet("color: #666666;")

        settings_layout.addWidget(self.current_mode_label)
        settings_layout.addWidget(self.current_params_label)

        left_layout.addWidget(settings_group)

        # å¿«é€Ÿé¢„è®¾
        preset_group = QGroupBox("å¿«é€Ÿé¢„è®¾")
        preset_group.setFont(QFont("Arial", 10, QFont.Bold))
        preset_layout = QHBoxLayout(preset_group)

        # é¢„è®¾æŒ‰é’®
        sensitive_btn = QPushButton("ğŸ”¥ æ•æ„Ÿæ¨¡å¼")
        sensitive_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF5722;
                color: white;
                font-weight: bold;
                padding: 8px 15px;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #E64A19;
            }
        """)
        sensitive_btn.clicked.connect(lambda: self._apply_preset('sensitive'))

        balanced_btn = QPushButton("âš–ï¸ å¹³è¡¡æ¨¡å¼")
        balanced_btn.setStyleSheet("""
            QPushButton {
                background-color: #4CAF50;
                color: white;
                font-weight: bold;
                padding: 8px 15px;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
        """)
        balanced_btn.clicked.connect(lambda: self._apply_preset('balanced'))

        conservative_btn = QPushButton("ğŸ›¡ï¸ ä¿å®ˆæ¨¡å¼")
        conservative_btn.setStyleSheet("""
            QPushButton {
                background-color: #2196F3;
                color: white;
                font-weight: bold;
                padding: 8px 15px;
                border: none;
                border-radius: 5px;
            }
            QPushButton:hover {
                background-color: #1976D2;
            }
        """)
        conservative_btn.clicked.connect(lambda: self._apply_preset('conservative'))

        preset_layout.addWidget(sensitive_btn)
        preset_layout.addWidget(balanced_btn)
        preset_layout.addWidget(conservative_btn)

        left_layout.addWidget(preset_group)

        return left_widget

    def _create_right_panel(self):
        """åˆ›å»ºå³ä¾§é¢æ¿"""
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)

        right_widget = QWidget()
        right_layout = QVBoxLayout(right_widget)

        # å®æ—¶ç›‘æµ‹åŒºåŸŸï¼ˆ3x2æ–¹æ ¼å¸ƒå±€ï¼‰
        monitor_group = QGroupBox("å®æ—¶ç›‘æµ‹")
        monitor_group.setFont(QFont("Arial", 12, QFont.Bold))
        monitor_layout = QVBoxLayout(monitor_group)

        # åˆ›å»º3x2æ–¹æ ¼å¸ƒå±€
        grid_widget = QWidget()
        grid_layout = QGridLayout(grid_widget)
        grid_layout.setSpacing(10)

        # äººè„¸æ£€æµ‹çŠ¶æ€
        self.face_status_widget = self._create_status_card("äººè„¸æ£€æµ‹", "ç­‰å¾…ä¸­", "#ffffff", "#333333")
        grid_layout.addWidget(self.face_status_widget, 0, 0)

        # æ‰“å“ˆæ¬ æ¦‚ç‡
        self.prob_status_widget = self._create_status_card("æ‰“å“ˆæ¬ æ¦‚ç‡", "0.000", "#e8f5e8", "#2e7d32")
        grid_layout.addWidget(self.prob_status_widget, 0, 1)

        # å˜´éƒ¨çŠ¶æ€
        self.mouth_status_widget = self._create_status_card("å˜´éƒ¨çŠ¶æ€", "æ­£å¸¸", "#fff3e0", "#e65100")
        grid_layout.addWidget(self.mouth_status_widget, 0, 2)

        # çœ¼éƒ¨çŠ¶æ€
        self.eye_status_widget = self._create_status_card("çœ¼éƒ¨çŠ¶æ€", "æ­£å¸¸", "#e3f2fd", "#1565c0")
        grid_layout.addWidget(self.eye_status_widget, 1, 0)

        # ç–²åŠ³çŠ¶æ€
        self.fatigue_status_widget = self._create_status_card("ç–²åŠ³çŠ¶æ€", "æ­£å¸¸", "#fce4ec", "#ad1457")
        grid_layout.addWidget(self.fatigue_status_widget, 1, 1)

        # è¿ç»­æ£€æµ‹
        self.consecutive_status_widget = self._create_status_card("è¿ç»­æ£€æµ‹", "0/30", "#f3e5f5", "#6a1b9a")
        grid_layout.addWidget(self.consecutive_status_widget, 1, 2)

        monitor_layout.addWidget(grid_widget)

        # è¿›åº¦æ¡
        progress_widget = QWidget()
        progress_layout = QHBoxLayout(progress_widget)
        progress_layout.addWidget(QLabel("æ£€æµ‹è¿›åº¦:"))
        self.progress_bar = QProgressBar()
        self.progress_bar.setStyleSheet("""
            QProgressBar {
                border: 2px solid #cccccc;
                border-radius: 5px;
                text-align: center;
                font-weight: bold;
            }
            QProgressBar::chunk {
                background-color: #4CAF50;
                border-radius: 3px;
            }
        """)
        progress_layout.addWidget(self.progress_bar)
        monitor_layout.addWidget(progress_widget)

        right_layout.addWidget(monitor_group)

        # ä¼šè¯ç»Ÿè®¡åŒºåŸŸ
        stats_group = QGroupBox("ä¼šè¯ç»Ÿè®¡")
        stats_group.setFont(QFont("Arial", 12, QFont.Bold))
        stats_layout = QVBoxLayout(stats_group)

        # åˆ›å»º2x3ç»Ÿè®¡æ–¹æ ¼å¸ƒå±€
        stats_grid_widget = QWidget()
        stats_grid_layout = QGridLayout(stats_grid_widget)
        stats_grid_layout.setSpacing(10)

        # ä¼šè¯æ—¶é—´
        self.time_status_widget = self._create_status_card("ä¼šè¯æ—¶é—´", "00:00", "#e3f2fd", "#1976d2")
        stats_grid_layout.addWidget(self.time_status_widget, 0, 0)

        # ç¼“å†²åŒº
        self.buffer_status_widget = self._create_status_card("ç¼“å†²åŒº", "0/30", "#f3e5f5", "#7b1fa2")
        stats_grid_layout.addWidget(self.buffer_status_widget, 0, 1)

        # æ€»æ£€æµ‹æ¬¡æ•°
        self.count_status_widget = self._create_status_card("æ€»æ£€æµ‹", "0", "#e8f5e8", "#388e3c")
        stats_grid_layout.addWidget(self.count_status_widget, 1, 0)

        # æ‰“å“ˆæ¬ æ¬¡æ•°
        self.yawn_status_widget = self._create_status_card("æ‰“å“ˆæ¬ ", "0", "#fff3e0", "#f57c00")
        stats_grid_layout.addWidget(self.yawn_status_widget, 1, 1)

        # çœ¨çœ¼æ¬¡æ•°ï¼ˆè·¨ä¸¤åˆ—ï¼‰
        self.blink_status_widget = self._create_status_card("çœ¨çœ¼æ¬¡æ•°", "0", "#fce4ec", "#c2185b")
        stats_grid_layout.addWidget(self.blink_status_widget, 2, 0, 1, 2)

        stats_layout.addWidget(stats_grid_widget)
        right_layout.addWidget(stats_group)

        # è­¦æŠ¥å†å²
        alert_group = QGroupBox("è­¦æŠ¥å†å²")
        alert_group.setFont(QFont("Arial", 12, QFont.Bold))
        alert_layout = QVBoxLayout(alert_group)

        self.alert_text = QTextEdit()
        self.alert_text.setMaximumHeight(150)
        self.alert_text.setStyleSheet("""
            QTextEdit {
                background-color: #ffffff;
                border: 2px solid #cccccc;
                border-radius: 5px;
                font-family: 'Consolas', monospace;
                font-size: 10px;
            }
        """)
        self.alert_text.append("ç³»ç»Ÿå¯åŠ¨ï¼Œç­‰å¾…å¼€å§‹æ£€æµ‹...")
        alert_layout.addWidget(self.alert_text)

        right_layout.addWidget(alert_group)

        # è®¾ç½®æ»šåŠ¨åŒºåŸŸ
        scroll_area.setWidget(right_widget)
        return scroll_area

    def _create_status_card(self, title, value, bg_color, text_color):
        """åˆ›å»ºçŠ¶æ€å¡ç‰‡"""
        card = QFrame()
        card.setFrameStyle(QFrame.StyledPanel | QFrame.Raised)
        card.setLineWidth(2)
        card.setStyleSheet(f"""
            QFrame {{
                background-color: {bg_color};
                border: 2px solid #cccccc;
                border-radius: 8px;
                padding: 5px;
            }}
        """)

        layout = QVBoxLayout(card)
        layout.setAlignment(Qt.AlignCenter)

        title_label = QLabel(title)
        title_label.setFont(QFont("Arial", 10, QFont.Bold))
        title_label.setStyleSheet(f"color: {text_color}; margin-bottom: 5px;")
        title_label.setAlignment(Qt.AlignCenter)

        value_label = QLabel(value)
        value_label.setFont(QFont("Arial", 12, QFont.Bold))
        value_label.setStyleSheet(f"color: {text_color};")
        value_label.setAlignment(Qt.AlignCenter)

        layout.addWidget(title_label)
        layout.addWidget(value_label)

        # ä¿å­˜value_labelçš„å¼•ç”¨ä»¥ä¾¿æ›´æ–°
        card.value_label = value_label

        return card

    def _set_style(self):
        """è®¾ç½®æ•´ä½“æ ·å¼"""
        self.setStyleSheet("""
            QMainWindow {
                background-color: #f0f0f0;
            }
            QGroupBox {
                font-weight: bold;
                border: 2px solid #cccccc;
                border-radius: 8px;
                margin-top: 10px;
                padding-top: 10px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
            }
        """)

    # ä»¥ä¸‹æ–¹æ³•å®Œå…¨ä¿æŒåŸæœ‰æ£€æµ‹é€»è¾‘ä¸å˜
    def _preprocess_frame(self, frame):
        """é¢„å¤„ç†å¸§ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        face_img, landmarks = extract_face_landmarks(frame, self.detector, self.predictor)

        if face_img is None or landmarks is None:
            return None, None, None

        face_resized = cv2.resize(face_img, FACE_SIZE)
        landmarks_norm = normalize_landmarks(landmarks, face_img.shape[:2])

        # è·å–äººè„¸åŒºåŸŸ
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.detector(gray)
        face_rect = faces[0] if len(faces) > 0 else None

        return face_resized, landmarks_norm, face_rect

    def _predict_yawn(self):
        """é¢„æµ‹æ‰“å“ˆæ¬ ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        if len(self.face_buffer) < SEQUENCE_LENGTH:
            return 0.0, 0

        faces = np.array(list(self.face_buffer))
        landmarks = np.array(list(self.landmark_buffer))

        faces_tensor = torch.from_numpy(faces).float().unsqueeze(0)
        landmarks_tensor = torch.from_numpy(landmarks).float().unsqueeze(0)

        faces_tensor = faces_tensor.permute(0, 1, 4, 2, 3)
        landmarks_tensor = landmarks_tensor.reshape(1, SEQUENCE_LENGTH, -1)
        faces_tensor = faces_tensor / 255.0

        faces_tensor = faces_tensor.to(self.device)
        landmarks_tensor = landmarks_tensor.to(self.device)

        with torch.no_grad():
            outputs = self.model(faces_tensor, landmarks_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            yawn_prob = probabilities[0, 1].item()
            prediction = 1 if yawn_prob > self.yawn_threshold.get() else 0

        return yawn_prob, prediction

    def _calculate_mouth_aspect_ratio(self, landmarks):
        """è®¡ç®—å˜´éƒ¨é•¿å®½æ¯”(MAR)ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        try:
            mouth_points = landmarks[48:68]
            A = np.linalg.norm(mouth_points[13] - mouth_points[19])
            B = np.linalg.norm(mouth_points[14] - mouth_points[18])
            C = np.linalg.norm(mouth_points[15] - mouth_points[17])
            D = np.linalg.norm(mouth_points[0] - mouth_points[6])
            mar = (A + B + C) / (3.0 * D)
            return mar
        except:
            return 0.0

    def _calculate_eye_aspect_ratio(self, landmarks):
        """è®¡ç®—çœ¼éƒ¨é•¿å®½æ¯”(EAR)ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        try:
            left_eye = landmarks[36:42]
            right_eye = landmarks[42:48]

            def eye_aspect_ratio(eye_points):
                A = np.linalg.norm(eye_points[1] - eye_points[5])
                B = np.linalg.norm(eye_points[2] - eye_points[4])
                C = np.linalg.norm(eye_points[0] - eye_points[3])
                ear = (A + B) / (2.0 * C)
                return ear

            left_ear = eye_aspect_ratio(left_eye)
            right_ear = eye_aspect_ratio(right_eye)
            avg_ear = (left_ear + right_ear) / 2.0

            return avg_ear
        except:
            return 0.3

    def _detect_blink(self, ear):
        """æ£€æµ‹çœ¨çœ¼å’Œé•¿æ—¶é—´é—­çœ¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        ear_threshold = 0.25
        current_time = time.time()

        if ear < ear_threshold:
            if self.eye_closed_frames == 0:
                self.eye_closed_start_time = current_time
            self.eye_closed_frames += 1
        else:
            if self.eye_closed_frames >= self.eye_closed_threshold:
                if current_time - self.last_blink_time > 0.3:
                    self.blink_count += 1
                    self.last_blink_time = current_time
                    self.recent_blinks.append(current_time)
                    return True

            self.eye_closed_frames = 0
            self.eye_closed_start_time = None

        return False

    def _evaluate_fatigue_status(self):
        """è¯„ä¼°ç–²åŠ³çŠ¶æ€ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        current_time = time.time()

        self.recent_yawns = [t for t in self.recent_yawns if current_time - t <= self.fatigue_window]
        self.recent_blinks = [t for t in self.recent_blinks if current_time - t <= self.fatigue_window]

        yawn_count_1min = len(self.recent_yawns)
        long_eye_closed = self.eye_closed_frames >= self.long_eye_closed_threshold

        if yawn_count_1min >= 3 or long_eye_closed:
            return "é‡åº¦ç–²åŠ³"
        elif yawn_count_1min >= 2:
            return "è½»åº¦ç–²åŠ³"
        else:
            return "æ­£å¸¸"

    def _draw_face_landmarks(self, frame, face_rect, landmarks):
        """ç»˜åˆ¶äººè„¸ç‰¹å¾ç‚¹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        if landmarks is not None and face_rect is not None:
            # ç»˜åˆ¶äººè„¸æ¡†
            cv2.rectangle(frame, (face_rect.left(), face_rect.top()),
                         (face_rect.right(), face_rect.bottom()), (255, 0, 0), 2)

            # ç»˜åˆ¶ç‰¹å¾ç‚¹ï¼ˆä¸åŸç‰ˆå®Œå…¨ä¸€è‡´ï¼‰
            for i, (x, y) in enumerate(landmarks):
                # è½¬æ¢ä¸ºå®é™…åæ ‡ï¼ˆä¸åŸç‰ˆå…¬å¼ä¸€è‡´ï¼‰
                actual_x = int(x * (face_rect.right() - face_rect.left()) + face_rect.left())
                actual_y = int(y * (face_rect.bottom() - face_rect.top()) + face_rect.top())

                # ä¸åŒåŒºåŸŸä½¿ç”¨ä¸åŒé¢œè‰²ï¼ˆä¸åŸç‰ˆä¸€è‡´ï¼‰
                if i < 17:  # è„¸éƒ¨è½®å»“ - è“è‰²
                    color = (255, 0, 0)
                elif i < 27:  # çœ‰æ¯› - ç»¿è‰²
                    color = (0, 255, 0)
                elif i < 36:  # é¼»å­ - é»„è‰²
                    color = (0, 255, 255)
                elif i < 48:  # çœ¼éƒ¨ - é’è‰²
                    color = (255, 255, 0)
                else:  # å˜´éƒ¨ - çº¢è‰²
                    color = (0, 0, 255)

                cv2.circle(frame, (actual_x, actual_y), 2, color, -1)

        return frame

    def _apply_preset(self, mode):
        """åº”ç”¨é¢„è®¾æ¨¡å¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        presets = {
            'sensitive': {
                'model_threshold': 0.5,
                'mar_threshold': 0.55,
                'consecutive_threshold': 20,
                'cooldown': 3.0,
                'name': 'ğŸ”¥ æ•æ„Ÿæ¨¡å¼',
                'color': '#FF5722'
            },
            'balanced': {
                'model_threshold': 0.6,
                'mar_threshold': 0.6,
                'consecutive_threshold': 30,
                'cooldown': 5.0,
                'name': 'âš–ï¸ å¹³è¡¡æ¨¡å¼',
                'color': '#4CAF50'
            },
            'conservative': {
                'model_threshold': 0.7,
                'mar_threshold': 0.7,
                'consecutive_threshold': 40,
                'cooldown': 7.0,
                'name': 'ğŸ›¡ï¸ ä¿å®ˆæ¨¡å¼',
                'color': '#2196F3'
            }
        }

        if mode in presets:
            preset = presets[mode]
            self.current_mode = mode

            # æ›´æ–°å‚æ•°
            self.yawn_threshold.set(preset['model_threshold'])
            self.mar_threshold.set(preset['mar_threshold'])
            self.consecutive_threshold = preset['consecutive_threshold']
            self.alert_cooldown.set(preset['cooldown'])

            # æ›´æ–°ç•Œé¢æ˜¾ç¤º
            self.current_mode_label.setText(f"å½“å‰æ¨¡å¼: {preset['name']}")
            self.current_mode_label.setStyleSheet(f"color: {preset['color']};")
            self.current_params_label.setText(
                f"æ¨¡å‹é˜ˆå€¼: {preset['model_threshold']:.2f} | MARé˜ˆå€¼: {preset['mar_threshold']:.2f} | "
                f"è¿ç»­é˜ˆå€¼: {preset['consecutive_threshold']}å¸§ | å†·å´: {preset['cooldown']:.1f}ç§’"
            )

            print(f"âœ… å·²åº”ç”¨{preset['name']}")

    def _start_detection(self):
        """å¼€å§‹æ£€æµ‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        if self.model is None:
            QMessageBox.critical(self, "é”™è¯¯", "æ¨¡å‹æœªåŠ è½½æˆåŠŸ")
            return

        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.cap = cv2.VideoCapture(self.camera_index)
        if not self.cap.isOpened():
            QMessageBox.critical(self, "é”™è¯¯", f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_index}")
            return

        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)

        # é‡ç½®çŠ¶æ€ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.session_start_time = time.time()
        self.yawn_count = 0
        self.blink_count = 0
        self.total_predictions = 0
        self.consecutive_yawns = 0
        self.last_yawn_time = 0
        self.last_blink_time = 0
        self.eye_closed_frames = 0
        self.recent_yawns.clear()
        self.recent_blinks.clear()
        self.face_buffer.clear()
        self.landmark_buffer.clear()

        # é‡ç½®è¿›åº¦æ¡å¹³æ»‘æ§åˆ¶å˜é‡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        self.last_detection_time = 0
        self.no_detection_frames = 0

        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)

        # å¯åŠ¨è§†é¢‘çº¿ç¨‹
        self.video_thread = VideoThread(self)
        self.video_thread.frame_ready.connect(self._update_video_display)
        self.video_thread.running = True
        self.video_thread.start()

        # æ·»åŠ è­¦æŠ¥è®°å½•
        self._add_alert("å¼€å§‹ç–²åŠ³æ£€æµ‹")
        print("ğŸš€ å¼€å§‹ç–²åŠ³æ£€æµ‹")

    def _stop_detection(self):
        """åœæ­¢æ£€æµ‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        if self.video_thread:
            self.video_thread.running = False
            self.video_thread.wait()
            self.video_thread = None

        if self.cap:
            self.cap.release()
            self.cap = None

        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)

        # é‡ç½®è§†é¢‘æ˜¾ç¤º
        self.video_label.setText("æ£€æµ‹å·²åœæ­¢")

        # æ·»åŠ è­¦æŠ¥è®°å½•
        self._add_alert("åœæ­¢ç–²åŠ³æ£€æµ‹")
        print("â¹ï¸ åœæ­¢ç–²åŠ³æ£€æµ‹")

    @pyqtSlot(np.ndarray, bool, float, int)
    def _update_video_display(self, frame, face_detected, yawn_prob, prediction):
        """æ›´æ–°è§†é¢‘æ˜¾ç¤º"""
        try:
            # è°ƒæ•´å›¾åƒå¤§å°
            display_frame = cv2.resize(frame, (640, 480))

            # è½¬æ¢ä¸ºQImage
            height, width, channel = display_frame.shape
            bytes_per_line = 3 * width
            q_image = QImage(display_frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()

            # è½¬æ¢ä¸ºQPixmapå¹¶æ˜¾ç¤º
            pixmap = QPixmap.fromImage(q_image)
            self.video_label.setPixmap(pixmap)

        except Exception as e:
            print(f"âŒ è§†é¢‘æ˜¾ç¤ºæ›´æ–°é”™è¯¯: {e}")

    def _add_alert(self, message):
        """æ·»åŠ è­¦æŠ¥è®°å½•"""
        current_time = time.strftime("%H:%M:%S")
        alert_message = f"{current_time} - {message}"
        self.alert_text.append(alert_message)

    def _update_gui(self):
        """æ›´æ–°GUIæ˜¾ç¤ºï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        if not self.video_thread or not self.video_thread.running:
            return

        try:
            # æ›´æ–°äººè„¸æ£€æµ‹çŠ¶æ€
            if hasattr(self, '_last_face_detected'):
                if self._last_face_detected:
                    self.face_status_widget.value_label.setText("æˆåŠŸ")
                    self.face_status_widget.value_label.setStyleSheet("color: #4CAF50; font-weight: bold;")
                else:
                    self.face_status_widget.value_label.setText("æœªæ£€æµ‹")
                    self.face_status_widget.value_label.setStyleSheet("color: #f44336; font-weight: bold;")

            # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
            if len(self.face_buffer) >= SEQUENCE_LENGTH:
                # æ›´æ–°æ‰“å“ˆæ¬ æ¦‚ç‡
                if hasattr(self, '_last_yawn_prob'):
                    self.prob_status_widget.value_label.setText(f"{self._last_yawn_prob:.3f}")
                    if self._last_yawn_prob > self.yawn_threshold.get():
                        color = "#f44336"  # çº¢è‰²
                    elif self._last_yawn_prob > 0.4:
                        color = "#FF9800"  # æ©™è‰²
                    else:
                        color = "#2e7d32"  # ç»¿è‰²
                    self.prob_status_widget.value_label.setStyleSheet(f"color: {color}; font-weight: bold;")

                # æ›´æ–°å˜´éƒ¨çŠ¶æ€
                if hasattr(self, '_last_mar'):
                    if self._last_mar > self.mar_threshold.get():
                        self.mouth_status_widget.value_label.setText("å¼ å¼€")
                        self.mouth_status_widget.value_label.setStyleSheet("color: #FF9800; font-weight: bold;")
                    else:
                        self.mouth_status_widget.value_label.setText("æ­£å¸¸")
                        self.mouth_status_widget.value_label.setStyleSheet("color: #4CAF50; font-weight: bold;")

                # æ›´æ–°çœ¼éƒ¨çŠ¶æ€
                if hasattr(self, '_last_ear'):
                    if self.eye_closed_frames >= self.long_eye_closed_threshold:
                        self.eye_status_widget.value_label.setText("é•¿æ—¶é—´é—­çœ¼")
                        self.eye_status_widget.value_label.setStyleSheet("color: #f44336; font-weight: bold;")
                    elif self._last_ear < 0.25:
                        self.eye_status_widget.value_label.setText("é—­åˆ")
                        self.eye_status_widget.value_label.setStyleSheet("color: #FF9800; font-weight: bold;")
                    elif self._last_ear < 0.3:
                        self.eye_status_widget.value_label.setText("çœ¯çœ¼")
                        self.eye_status_widget.value_label.setStyleSheet("color: #FFC107; font-weight: bold;")
                    else:
                        self.eye_status_widget.value_label.setText("æ­£å¸¸")
                        self.eye_status_widget.value_label.setStyleSheet("color: #4CAF50; font-weight: bold;")

                # æ›´æ–°ç–²åŠ³çŠ¶æ€
                fatigue_level = self._evaluate_fatigue_status()
                self.fatigue_status_widget.value_label.setText(fatigue_level)
                if fatigue_level == "æ­£å¸¸":
                    color = "#4CAF50"
                elif fatigue_level == "è½»åº¦ç–²åŠ³":
                    color = "#FFC107"
                else:  # é‡åº¦ç–²åŠ³
                    color = "#f44336"
                self.fatigue_status_widget.value_label.setStyleSheet(f"color: {color}; font-weight: bold;")

                # æ›´æ–°è¿ç»­æ£€æµ‹æ˜¾ç¤º
                self.consecutive_status_widget.value_label.setText(f"{self.consecutive_yawns}/{self.consecutive_threshold}")

                # æ›´æ–°è¿›åº¦æ¡ï¼ˆå¹³æ»‘è¿›åº¦æ¡é€»è¾‘ï¼‰
                progress = (self.consecutive_yawns / self.consecutive_threshold) * 100
                self.progress_bar.setValue(int(progress))

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if self.session_start_time:
                elapsed = int(time.time() - self.session_start_time)
                minutes, seconds = divmod(elapsed, 60)
                self.time_status_widget.value_label.setText(f"{minutes:02d}:{seconds:02d}")

            self.buffer_status_widget.value_label.setText(f"{len(self.face_buffer)}/{SEQUENCE_LENGTH}")
            self.count_status_widget.value_label.setText(f"{self.total_predictions}")
            self.yawn_status_widget.value_label.setText(f"{self.yawn_count}")
            self.blink_status_widget.value_label.setText(f"{self.blink_count}")

        except Exception as e:
            print(f"âŒ GUIæ›´æ–°é”™è¯¯: {e}")

    def run(self):
        """è¿è¡ŒGUI"""
        print("ğŸ¯ PyQtç–²åŠ³æ£€æµ‹ç³»ç»Ÿå¯åŠ¨")
        print(f"ğŸ“± çª—å£å¤§å°: 1400x900")
        print(f"ğŸ“œ å³ä¾§é¢æ¿æ”¯æŒæ»šåŠ¨")
        print(f"ğŸ® é»˜è®¤æ¨¡å¼: å¹³è¡¡æ¨¡å¼")
        print(f"ğŸ“· æ£€æµ‹åˆ°æ‘„åƒå¤´: ç´¢å¼• {self.camera_index}")
        self.show()

def main():
    """ä¸»å‡½æ•°"""
    app = QApplication(sys.argv)

    # è®¾ç½®åº”ç”¨ç¨‹åºæ ·å¼
    app.setStyle('Fusion')

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = os.path.join(MODEL_SAVE_PATH, "best_model.pth")
    if not os.path.exists(model_path):
        QMessageBox.critical(None, "é”™è¯¯", f"æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨")
        return

    # æ£€æŸ¥dlibæ–‡ä»¶
    if not os.path.exists(DLIB_PREDICTOR_PATH):
        QMessageBox.critical(None, "é”™è¯¯", f"dlibæ–‡ä»¶ {DLIB_PREDICTOR_PATH} ä¸å­˜åœ¨")
        return

    try:
        window = FatigueDetectionGUI(model_path)
        window.run()

        print("ğŸ¯ PyQtç–²åŠ³æ£€æµ‹ç³»ç»Ÿå¯åŠ¨")
        print("ğŸ“± ç°ä»£åŒ–ç•Œé¢è®¾è®¡")
        print("ğŸ¨ æ”¯æŒä¸»é¢˜æ ·å¼")
        print("ğŸ“œ è‡ªåŠ¨æ»šåŠ¨æ”¯æŒ")
        print("ğŸ”§ ä¿æŒåŸæœ‰æ£€æµ‹é€»è¾‘")

        sys.exit(app.exec_())

    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        QMessageBox.critical(None, "é”™è¯¯", f"ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
